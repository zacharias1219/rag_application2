# rag_application2

## Modules
pandas as pd
A custom module llama_index with its submodules
A custom module llama_index.llms with its submodules
A custom module llama_index.prompts.prompts with its submodules
A custom module langchain.embeddings.huggingface with its submodules
A custom module llama_index.llms with its submodules
A custom module llama_index.prompts.prompts with its submodules
Additionally, an instance of the HuggingFaceLLM class was created and assigned to the variable llm.
A custom module llama_index with its submodules
A custom module llama_index.embeddings with its submodules
Additionally, an instance of the LangchainEmbedding class was created and assigned to the variable embed_model.

## Steps
1. Load Data and give system prompt
2. Initialized HuggingFaceLLM with various parameters.
3. Used service context to divide chunk size and implimented vector store index.
4. Initialized querry engine
